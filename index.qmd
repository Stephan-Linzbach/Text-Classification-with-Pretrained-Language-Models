---
title:  Fine-tuning (or customization) a LLM for text classification with small data
author: Stephan Linzbach (GESIS)
bibliography: references.bib
csl: apa.csl
format:
  html: default
  ipynb: default
---

# Text Classification Tutorial

## 1) Learning Objectives

This tutorial has the following learning objectives:
-	Learning how to work with large language models (RoBERTa)
-	Customizing (fine-tuning) a large language model for a text classification task in any language (100+ languages supported)
-	Low-resource learning (with only a few hundred examples) using the SAM optimizer
- Multi-label and Multi-output text classification


## 2) Description

This step-by-step tutorial provides an accessible introduction to customizing (fine-tuning) a pre-trained multilingual language model (RoBERTa) for text classification tasks. It demonstrates how to use the model's existing knowledge to classify text accurately, even with a small set of labeled examples. It takes input as JSON files with text documents and their corresponding labels for training, validating and testing. It covers using specialized models for English, German, and French while employing XLM-RoBERTa for over 100 additional languages.

## 3) Target Audience (Difficulty Level)

-	Social scientists willing to learn about using large language models with basic prior understanding of it
-	Social scientists with expertise in large-language models, interested in fine-tuning for multiple languages from only few examples.
-	Computer scientists interested in learning about how large-language models are used for social text classification.
-	Advanced NLP researchers and professors looking for tutorials that can help their students in learning new topics.

## 4) Prerequisites

Use this tutorial preferably in [Google Colab](https://colab.research.google.com/github/Stephan-Linzbach/Text-Classification-with-Pretrained-Language-Models/blob/main/textclassification_tutorial.ipynb), as the setup depends on the pre-installed packages of the Colab environment.

## 5) Environment Setup

To follow this tutorial, ensure the following:

- Python >= 3.7 installed.
- Install required libraries by running:
  ```bash
  pip install -r requirements.txt
  ```

## 6) Tutorial Content

**1. Introduction to the Task**
- Explanation of single-label classification and its applications.

**2. Data Preparation**
- Loading the data
- Loading language-specific language model

```
language = "Which language do you use? ('english', 'german', 'french') "

print(f"MMhhh interesting your data is written in {language}. Let's load a fitting PLM!")

if language == 'english':
  model_name = "roberta-base"
elif language == 'german':
  model_name = "benjamin/roberta-base-wechsel-german"
elif language == 'french':
  model_name = "camembert-base"
else:
  print(f"Seems like we have no model available for {language}.")
  print("We will load a mulitlingual language model. It knows text from 100 languages.")
  model_name = 'xlm-roberta-base'

print(f"We loaded {model_name} for {language}.")

# Output:
# Which language do you use? ('english', 'german', 'french') english
# MMhhh interesting your data is written in english. Let's load a fitting PLM!
# We loaded roberta-base for english.
```



**3. Defining the Classification Task**
- Defining the way data points are classified.
- Setting the number of different labels.

```
# Prompt the user to select the classification type
decision_type = "Do you want to classify by 'choosing' or 'deciding'? "
# Validate the input
assert decision_type in ['choosing', 'deciding'], "Invalid input! Please enter 'choosing' or 'deciding'."
# Ensure the labels align with the selected classification type
if decision_type == 'deciding':
    assert isinstance(train['Labels'][0], list), (
        "For 'deciding', labels should be a list (e.g., ['apple', 'banana'])."
    )
else:
    assert not isinstance(train['Labels'][0], list), (
        "For 'choosing', each label should be a single value (e.g., 'apple')."
    )
# Output:
# Do you want to classify by 'choosing' or 'deciding'? choosing
```

**4. Setting up the Model**
- Defining training parameters: batch size, learning rate, number of epochs.
- Defining training infrastructure: optimizers, a learning rate scheduler, a model, and a tokenizer.

```
# Model configuration
model_config = {'pretrained_model_name_or_path': model_name,
                'num_labels': output_size,
                'problem_type': objective,
                'id2label': id2label,
                'label2id': label2id}

# Training Hyperparameters
batch_size = 64
lr = 1e-4
num_epochs = 3
warm_up_rate = 0.1
num_training_steps = (len(train['Labels'])//batch_size)*num_epochs
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
```

**5. Training**
- Implementing the training loop with learning rate scheduling and optimizer setup.
- Running the training and validation loop.
- Load the best-performing model.

```
for epoch in range(num_epochs): # Repeat num_epochs times

  for batch_idx, batch in enumerate(train_dataloader): # Train the model on the batch
    input_ids, attention_mask, y = batch[0].to(device), batch[1].to(device), batch[2].to(device)

    output = model(input_ids, attention_mask, labels=y)
    loss = output.loss
    loss.backward()

# Output:
# Train: Epoch 2, Train step 4, Loss 0.09070442616939545, learning_rate 1.4303513272105057e-05
#  Train: Epoch 2, Train step 5, Loss 0.0538533590734005, learning_rate 3.7138015365554833e-06
# Train: Epoch 2, Train step 6, Loss 0.05279867351055145, learning_rate 0.0
# Validation: Epoch 2, Train step 6, Loss 0.050605375319719315, old best/epoch .0882/1
# **** END EPOCH 2 ****
# **** FINISHED TRAINING FOR N=2 ****
# BEST EPOCH: 2
# BEST LOSS: 0.050605375319719315
```



**6. Evaluation**
- Testing the model on unseen data.
- Generating a classification report with metrics (precision, recall, F1-score).
- Interpreting results and identifying potential improvements.
- Understanding the classification report (precision, recall, F1-score, and accuracy).
- Analyzing the model's performance on the test set.



```
print(classification_report(test_y, y_pred, target_names=label2id.keys(), zero_division=True))

# Output:
#                precision    recall  f1-score   support
#
#   is_correct       1.00      0.00      0.00        64
# is_incorrect       0.67      1.00      0.80       128
#
#     accuracy                           0.67       192
#    macro avg       0.83      0.50      0.40       192
# weighted avg       0.78      0.67      0.53       192
```

## 7) Duration

This tutorial will take approximately 1–2 hours.

## 8) Social Science Use Cases 

**Stance Detection on Newspaper Articles**

Use Case:
	Imagine you want to understand the different arguments to defend a negative stance towards a specific political party.
Method Application:
	Create a training dataset that contains news articles that are 'Against', 'In Favor', or 'Unconnected' to the political party in question.
	You can now use the tutorial to learn how to train a model to learn the labels you have decided.
	With this model, you can categorize a big dataset automatically. 
	Now you can analyze only those articles that are marked as 'Against' by the model to understand the arguments used to argue against the specific political party.


**Topic Classification for Social Science Survey Questions**

Use Case:
	Imagine you want to group questions by their topic to subsequently group the answers into more conclusive insights than just the independent answers.
Method Application:
	Think about a taxonomy of topics that is interesting to your analysis.
	Create a training dataset that contains a small fraction of the questions that you are interested in.
	Label the questions with the topic you associate with them.
	In the best case, several people perform this same task (Maybe ChatGPT can help you as well).
	Next, you can train the model using the tutorial to predict your topic given the associated question.
	With the fitted model you can now label all questions.
	
**Emotion Detection in Social Media Posts**

Use Case:
	Imagine you want to understand the topics and writing styles associated with a specific topic.
Method Application:
	If you have a large dataset of social media posts you can use the smileys as indication of the emotion mentioned in the post.
	Label each of the social media posts with the smiley used in it.
	Train a model to predict the emoji from the text - make sure to remove the emoji from the training data.
	Now you can apply this to all text even those without emojis.
	Choose the emoji that best describes the emotion you are interested in.
	Now you can focus your analysis on the posts that your model associates with the chosen emoji.

## 9) Flow Diagram 

The flow involves:

1. Data Preparation.
2. Model configuration and initialization.
3. Training and validation.
4. Evaluation and result interpretation.

## 10) How to Use

1. Clone the repository or download the notebook.
2. Follow the steps sequentially in the notebook to preprocess data, fine-tune the model, and evaluate it.
3. Modify hyperparameters or use a different dataset for custom tasks.

## 11) Conclusion

This tutorial covers the end-to-end pipeline for text classification using fine-tuning of a pre-trained model. By following the steps, you will acquire the skills to apply similar techniques to your own datasets and tasks.

## 12) References

Conneau, A. (2019). Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116.
Liu, Y. (2019). Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 364.
Martin, L., Muller, B., Suárez, P. J. O., Dupont, Y., Romary, L., de La Clergerie, É. V. & Sagot, B. (2019). CamemBERT: a tasty French language model. arXiv preprint arXiv:1911.03894.
Minixhofer, B., Paischer, F., & Rekabsaz, N. (2021). WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models. arXiv preprint arXiv:2112.06598.
Foret, P., Kleiner, A., Mobahi, H., & Neyshabur, B. (2020). Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412.

## 13) Contact Details

For questions or feedback, contact:

- **Stephan Linzbach**: [Stephan.Linzbach@gesis.org](mailto:Stephan.Linzbach@gesis.org)

## Acknowledgments

This tutorial uses resources from the Hugging Face library and PyTorch framework.

